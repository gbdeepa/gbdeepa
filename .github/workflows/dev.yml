name: Dev-Depoyment

on: 
  workflow_dispatch:
  pull_request:
    branches:
      # - develop
      - main

permissions:
  id-token: write
  contents: write
 
env:
  ENVIRONMENT: dev 


jobs:

  Init:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Import env
        uses: cardinalby/export-env-action@v1
        with:
          envFile: 'variables.env'
      - name: Output
        run: |
          echo ${{ env.JDBC_VERSION }}
      - name: Create Deployment Bucket
        run: |
          echo "DEPLOYMENT_BUCKET=fj-spark-deploy"  >> $GITHUB_ENV
          echo "PROJECT_BUCKET=fj-s3-glue-snowflake"  >> $GITHUB_ENV
    outputs:
      env: ${{ toJson(env) }}
      account: ${{ env.AWS_ACCOUNT }}
      
      
  BuildAndVerify:
    name: Build And Verify
    env: ${{ fromJson(needs.Init.outputs.env) }}
    needs: [Init]
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.8"]
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install flake8 pytest coverage
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
      - name: Test with pytest
        run: |
          coverage run --source=src -m pytest unit


  DeployCode:
    name: Deploy Code
    env: ${{ fromJson(needs.Init.outputs.env) }}
    needs: [Init,BuildAndVerify]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-region: us-east-1
          role-to-assume: arn:aws:iam::858366249668:role/github-oidc-role
          role-session-name: OIDCSession
      - name: Copy files to the test website with the AWS CLI
        run: |
          # download the additional spark jars
          mkdir connector
          cd connector
          wget https://repo1.maven.org/maven2/net/snowflake/snowflake-jdbc/${{ env.JDBC_VERSION }}/snowflake-jdbc-${{ env.JDBC_VERSION }}.jar
          wget https://repo1.maven.org/maven2/net/snowflake/spark-snowflake_${{ env.SCALA_VERSION }}/${{ env.CONNECTOR_VERSION }}-spark_${{ env.SPARK_VERSION }}/spark-snowflake_${{ env.SCALA_VERSION }}-${{ env.CONNECTOR_VERSION }}-spark_${{ env.SPARK_VERSION }}.jar
          cd ../
          aws s3 sync --delete --exact-timestamps . s3://${{ ENV.DEPLOYMENT_BUCKET }}
          aws s3 cp src/code s3://${{ ENV.PROJECT_BUCKET }}/code --recursive
        shell: bash
        
  DeployCloudformation:
    name: Deploy Cloudformation
    env: ${{ fromJson(needs.Init.outputs.env) }}
    needs: [Init,BuildAndVerify,DeployCode]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
            aws-region: us-east-1
            role-to-assume: arn:aws:iam::858366249668:role/github-oidc-role
            role-session-name: OIDCSession
      - name: Deploy Cloudformation
        uses: aws-actions/aws-cloudformation-github-deploy@master
        with:
          name: snowflake-glue-stack
          template: cloudformation.yaml
          capabilities: CAPABILITY_NAMED_IAM
          no-fail-on-empty-changeset: "1"
          parameter-overrides: >-
            ProjectBucket=${{ env.PROJECT_BUCKET }},
            CodeBucket=${{ env.PROJECT_BUCKET }},
            SecretName=${{ env.SECRET_NAME }}              
          tags: |
            ALLOW_GHA_DELETE: "TRUE"
